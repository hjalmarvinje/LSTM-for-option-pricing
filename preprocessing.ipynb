{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(path, filenames):\n",
    "    \"\"\"\n",
    "    Reads all files and returns a dataframe with only the specificed columns\n",
    "    \"\"\"\n",
    "    return pd.concat((pd.read_csv(path + f, skipinitialspace=True) for f in filenames))\n",
    "\n",
    "def process_options(df_opt, call = True):\n",
    "    \"\"\"\n",
    "    Cleans up column names and add time to live (Ttl) column to the dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    keys = {key: key[key.find(\"[\")+1:key.find(\"]\")][0] + key[key.find(\"[\")+1:key.find(\"]\")][1:].lower()  for key in df_opt.keys()}\n",
    "    df_opt = df_opt.rename(columns=keys)\n",
    "\n",
    "    if call:\n",
    "        keys = {\"C_ask\": \"Ask\", \"C_bid\": \"Bid\"}\n",
    "    else:\n",
    "        keys = {\"P_ask\": \"Ask\", \"P_bid\": \"Bid\"}\n",
    "    df_opt = df_opt.rename(columns=keys)\n",
    "\n",
    "    df_opt[\"Quote_date\"] = pd.to_datetime(df_opt[\"Quote_date\"])\n",
    "    df_opt[\"Expire_date\"] = pd.to_datetime(df_opt[\"Expire_date\"])\n",
    "    df_opt[\"Ttl\"] = df_opt.apply(lambda row: (row.Expire_date - row.Quote_date).days, axis = 1)\n",
    "\n",
    "    df_opt[\"Moneyness\"] = df_opt[\"Underlying_last\"] / df_opt[\"Strike\"]\n",
    "    \n",
    "    df_vol = calculate_volatility(df_opt)\n",
    "    df_vol.info()\n",
    "    df_opt = pd.merge(df_opt, df_vol, on =\"Quote_date\", how = \"left\")\n",
    "\n",
    "    columns = [\"Quote_date\", \"Expire_date\",  \"Underlying_last\", \"Strike\", \"Moneyness\", \"Ask\", \"Bid\", \"Ttl\", \"Volatility\"]\n",
    "    df_opt = df_opt[columns]\n",
    "    df_opt = df_opt[df_opt[\"Ttl\"] != 0]\n",
    "    return df_opt[columns]\n",
    "\n",
    "def calculate_volatility(df):\n",
    "    \"\"\"\n",
    "    Calculate underlying volatility from dataset of options\n",
    "    Returns annualized 90 days moving average volatility\n",
    "    \"\"\"\n",
    "    df_vol = df[[\"Quote_date\", \"Underlying_last\"]].drop_duplicates()\n",
    "    df_vol[\"Volatility\"] = np.log(df_vol[\"Underlying_last\"] / df_vol[\"Underlying_last\"].shift()).rolling(90).std()*(252**0.5)\n",
    "    return df_vol[[\"Quote_date\", \"Volatility\"]]\n",
    "\n",
    "def process_rates(df_r):\n",
    "    \"\"\"\n",
    "    Rename rate duration\n",
    "    \"\"\"\n",
    "    df_r[\"Date\"] = pd.to_datetime(df_r[\"Date\"])\n",
    "    df_r = df_r.rename(columns = {\"Date\" : \"Quote_date\", \"3 Mo\": \"R\"})\n",
    "    #rate_keys = {key: key if key == \"Date\" else int(key.split(\" \")[0])*30 if key.split(\" \")[1] == \"Mo\" else int(key.split(\" \")[0])*365  for key in df_r.keys()}\n",
    "    #df_r = df_r.rename(columns=rate_keys)\n",
    "    columns = [\"Quote_date\", \"R\"]\n",
    "    return df_r[columns]\n",
    "\n",
    "def combine_opt_r(df_opt, df_r):\n",
    "    \"\"\"\n",
    "    Combines the dataset for options and rates\n",
    "    \"\"\"\n",
    "    #df_opt[\"R\"] = df_opt.apply(lambda row : df_rates[str(min(df_r.drop([\"Date\"], axis = 1).keys(), key = lambda x:abs(int(x)-row.Ttl)))][row.Quote_date], axis = 1)\n",
    "    df_opt = pd.merge(df_opt, df_r, on =\"Quote_date\", how = \"left\")\n",
    "    return df_opt\n",
    "\n",
    "def get_model_dataset(path_opt, filenames_opt, path_r, filenames_r, call = True):\n",
    "    \"\"\"\n",
    "    Wrapper function to extract option data and rates. Returns a combined dataframe\n",
    "    \"\"\"\n",
    "    df_opt = read_files(path_opt, filenames_opt)\n",
    "    df_r = read_files(path_r, filenames_r)\n",
    "    df_opt = process_options(df_opt, call)\n",
    "    df_r = process_rates(df_r)\n",
    "    df = combine_opt_r(df_opt, df_r)\n",
    "    return df.dropna() #TODO: Fix handling of nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 192 entries, 0 to 172733\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   Quote_date  192 non-null    datetime64[ns]\n",
      " 1   Volatility  102 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 4.5 KB\n",
      "        Quote_date Expire_date  Underlying_last   Strike  Moneyness    Ask  \\\n",
      "725110  2022-05-09  2022-05-10          3993.26   3100.0   1.288148  893.3   \n",
      "725111  2022-05-09  2022-05-10          3993.26   3200.0   1.247894  792.9   \n",
      "725112  2022-05-09  2022-05-10          3993.26   3300.0   1.210079  692.2   \n",
      "725113  2022-05-09  2022-05-10          3993.26   3400.0   1.174488  592.2   \n",
      "725114  2022-05-09  2022-05-10          3993.26   3500.0   1.140931  493.0   \n",
      "...            ...         ...              ...      ...        ...    ...   \n",
      "1533707 2022-09-30  2026-12-18          3589.70   8800.0   0.407920   31.4   \n",
      "1533708 2022-09-30  2026-12-18          3589.70   9000.0   0.398856   29.5   \n",
      "1533709 2022-09-30  2026-12-18          3589.70   9200.0   0.390185   16.2   \n",
      "1533710 2022-09-30  2026-12-18          3589.70   9600.0   0.373927   24.5   \n",
      "1533711 2022-09-30  2026-12-18          3589.70  10000.0   0.358970   21.8   \n",
      "\n",
      "           Bid   Ttl  Volatility     R  \n",
      "725110   886.3     1    0.233070  0.92  \n",
      "725111   785.4     1    0.233070  0.92  \n",
      "725112   685.8     1    0.233070  0.92  \n",
      "725113   585.4     1    0.233070  0.92  \n",
      "725114   485.9     1    0.233070  0.92  \n",
      "...        ...   ...         ...   ...  \n",
      "1533707   10.0  1540    0.234276  3.33  \n",
      "1533708    6.1  1540    0.234276  3.33  \n",
      "1533709   11.2  1540    0.234276  3.33  \n",
      "1533710    3.3  1540    0.234276  3.33  \n",
      "1533711    7.3  1540    0.234276  3.33  \n",
      "\n",
      "[776381 rows x 10 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 776381 entries, 725110 to 1533711\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count   Dtype         \n",
      "---  ------           --------------   -----         \n",
      " 0   Quote_date       776381 non-null  datetime64[ns]\n",
      " 1   Expire_date      776381 non-null  datetime64[ns]\n",
      " 2   Underlying_last  776381 non-null  float64       \n",
      " 3   Strike           776381 non-null  float64       \n",
      " 4   Moneyness        776381 non-null  float64       \n",
      " 5   Ask              776381 non-null  float64       \n",
      " 6   Bid              776381 non-null  float64       \n",
      " 7   Ttl              776381 non-null  int64         \n",
      " 8   Volatility       776381 non-null  float64       \n",
      " 9   R                776381 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(7), int64(1)\n",
      "memory usage: 65.2 MB\n"
     ]
    }
   ],
   "source": [
    "path_opt = \"./data/options/\"\n",
    "filenames_opt = [\"spx_eod_\" + str(year) + (str(month) if month >= 10 else \"0\"+str(month)) +\".txt\" for year in range(2022, 2022) for month in range(1, 13)] + [\"spx_eod_2022\" + (str(month) if month >= 10 else \"0\"+str(month)) +\".txt\" for month in range(1, 10)]\n",
    "#filenames_opt = [\"spx_eod_202209.txt\"]\n",
    "path_r = \"./data/rates/\"\n",
    "filenames_r = [\"yield-curve-rates-2022.csv\", \"yield-curve-rates-1990-2021.csv\"]\n",
    "\n",
    "df_read = get_model_dataset(path_opt, filenames_opt, path_r, filenames_r, True)\n",
    "print(df_read)\n",
    "df_read.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.2881483870967743 8.0 0.92 0.23306972873412843 900.1 906.4]\n",
      " [1.24789375 8.0 0.92 0.23306972873412843 800.2 806.4]\n",
      " [1.210078787878788 8.0 0.92 0.23306972873412843 700.2 706.4]\n",
      " [1.1744882352941177 8.0 0.92 0.23306972873412843 600.2 606.4]\n",
      " [1.1409314285714287 8.0 0.92 0.23306972873412843 503.1 506.6]\n",
      " [1.1092388888888889 8.0 0.92 0.23306972873412843 403.2 406.4]\n",
      " [1.0792594594594596 8.0 0.92 0.23306972873412843 303.2 306.8]\n",
      " [1.050857894736842 8.0 0.92 0.23306972873412843 203.3 206.9]\n",
      " [1.0372103896103897 8.0 0.92 0.23306972873412843 153.6 157.1]\n",
      " [1.0305187096774193 8.0 0.92 0.23306972873412843 129.0 132.0]]\n",
      "(595433, 32)\n",
      "[[Timestamp('2022-05-16 00:00:00') Timestamp('2022-05-17 00:00:00')\n",
      "  4009.25 ... 0.007693282197183571 0.21576335786370068\n",
      "  0.20750958731612387]\n",
      " [Timestamp('2022-05-16 00:00:00') Timestamp('2022-05-17 00:00:00')\n",
      "  4009.25 ... 0.007693282197183571 0.1918162859266007 0.18461450403525845]\n",
      " [Timestamp('2022-05-16 00:00:00') Timestamp('2022-05-17 00:00:00')\n",
      "  4009.25 ... 0.007693282197183571 0.16784524294652062 0.161719420754393]\n",
      " ...\n",
      " [Timestamp('2022-09-14 00:00:00') Timestamp('2026-12-18 00:00:00')\n",
      "  3946.87 ... 0.4140638680113904 0.001821799266486085\n",
      "  0.004682044530936982]\n",
      " [Timestamp('2022-09-15 00:00:00') Timestamp('2026-12-18 00:00:00')\n",
      "  3901.27 ... 0.4485401671612461 0.002157393868207206\n",
      "  0.002552801785816496]\n",
      " [Timestamp('2022-09-16 00:00:00') Timestamp('2026-12-18 00:00:00')\n",
      "  3873.28 ... 0.3260484927329159 0.0019895965673466455\n",
      "  0.0020491099536374567]]\n",
      "(44722, 32)\n",
      "[[Timestamp('2022-05-16 00:00:00') Timestamp('2022-05-17 00:00:00')\n",
      "  4009.25 ... 0.007693282197183571 0.21576335786370068\n",
      "  0.20750958731612387]\n",
      " [Timestamp('2022-05-16 00:00:00') Timestamp('2022-05-17 00:00:00')\n",
      "  4009.25 ... 0.007693282197183571 0.1918162859266007 0.18461450403525845]\n",
      " [Timestamp('2022-05-16 00:00:00') Timestamp('2022-05-17 00:00:00')\n",
      "  4009.25 ... 0.007693282197183571 0.16784524294652062 0.161719420754393]\n",
      " ...\n",
      " [Timestamp('2022-09-14 00:00:00') Timestamp('2026-12-18 00:00:00')\n",
      "  3946.87 ... 0.4140638680113904 0.001821799266486085\n",
      "  0.004682044530936982]\n",
      " [Timestamp('2022-09-15 00:00:00') Timestamp('2026-12-18 00:00:00')\n",
      "  3901.27 ... 0.4485401671612461 0.002157393868207206\n",
      "  0.002552801785816496]\n",
      " [Timestamp('2022-09-16 00:00:00') Timestamp('2026-12-18 00:00:00')\n",
      "  3873.28 ... 0.3260484927329159 0.0019895965673466455\n",
      "  0.0020491099536374567]]\n"
     ]
    }
   ],
   "source": [
    "def lag_features(df, features, seq_length):\n",
    "    \"\"\"\n",
    "    Transforms a raw 2D dataframe of option data into 2D dataframe of sequence data\n",
    "    Last 2 indexes per sequence is bid and ask price\n",
    "    The len(features)*seq_length features before are sequences of features\n",
    "    \"\"\"\n",
    "    df = df.sort_values([\"Expire_date\", \"Strike\", \"Ttl\"], ascending = [True, True, False])\n",
    "\n",
    "    for step in range(seq_length):\n",
    "        for feature in features:\n",
    "            df[feature + \" - \" + str(step)] = df[feature].shift(step)\n",
    "    \n",
    "    df[\"Check_strike\"] = df[\"Strike\"] == df[\"Strike\"].shift(seq_length-1)\n",
    "    df[\"Check_expire\"] = df[\"Expire_date\"] == df[\"Expire_date\"].shift(seq_length-1)\n",
    "    df = df[(df[\"Check_strike\"] == True) & (df[\"Check_expire\"] == True)]\n",
    "    df = df.drop([\"Check_strike\", \"Check_expire\"], axis=1)\n",
    "    df[[\"Bid_last\", \"Ask_last\"]] = df[[\"Bid\", \"Ask\"]]\n",
    "    return df\n",
    "\n",
    "def create_train_test(df, features, split_date, seq_length):\n",
    "    train = lag_features(df[df[\"Quote_date\"] < split_date], features, seq_length).to_numpy()\n",
    "    test = lag_features(df[df[\"Quote_date\"] >= split_date], features, seq_length).to_numpy()\n",
    "    print(train[:10][:,-6:])\n",
    "    train[:, -len(features)*seq_length - 2:], test[:, -len(features)*seq_length - 2:] = min_max_scale(train[:, -len(features)*seq_length-2:], test[:, -len(features)*seq_length-2:])\n",
    "    #return np.reshape(train_x, (len(train_x), seq_length, len(features))), train_y, np.reshape(test_x, (len(test_x), seq_length, len(features))), test_y\n",
    "    return train, test #TODO: Move reshaping to modell\n",
    "\n",
    "def min_max_scale(train, test):\n",
    "    scaler = MinMaxScaler()\n",
    "    train = scaler.fit_transform(train)\n",
    "    test = scaler.transform(test)\n",
    "    return train, test\n",
    "\n",
    "features = [\"Moneyness\", \"Ttl\", \"R\", \"Volatility\"]\n",
    "train, test = create_train_test(df_read, features,  \"2022-09-18\", 5)\n",
    "\n",
    "print(train.shape)\n",
    "print(train)\n",
    "print(test.shape)\n",
    "print(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.021583693424441226 0.0005963029218843171 0.01315789473684209\n",
      "  0.007693282197183571 0.21576335786370068 0.20750958731612387]\n",
      " [0.02064066788222127 0.0005963029218843171 0.01315789473684209\n",
      "  0.007693282197183571 0.1918162859266007 0.18461450403525845]\n",
      " [0.01975479540316616 0.0005963029218843171 0.01315789473684209\n",
      "  0.007693282197183571 0.16784524294652062 0.161719420754393]\n",
      " ...\n",
      " [0.0011058482682001474 0.936195587358378 0.8464912280701755\n",
      "  0.7318589528792989 0.001821799266486085 0.0026214870356590925]\n",
      " [0.0012453765445564653 0.9355992844364937 0.8728070175438598\n",
      "  0.7647292388261464 0.0019176834384064053 0.0027130673687825544]\n",
      " [0.0009140320279708743 0.9350029815146094 0.8771929824561404\n",
      "  0.8866141545670789 0.001821799266486085 0.005483372445767271]]\n"
     ]
    }
   ],
   "source": [
    "print(train[:-10][:,-6:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d22c5043c0ee61c8547bd88adb0f85d3d6a0a630c1da4282026f99271dac814"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
