{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.18.0-cp38-cp38-macosx_10_14_x86_64.whl (12.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow_addons) (21.3)\n",
            "Collecting typeguard>=2.7\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from packaging->tensorflow_addons) (3.0.9)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.18.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpw7k8d3OnVe",
        "outputId": "c81879b5-b79d-4cd3-9975-ada72035c1f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcxwjSuFwiip"
      },
      "outputs": [],
      "source": [
        "# Weights and Biases\n",
        "#!pip install -q wandb\n",
        "# Tensorflow\n",
        "#!pip install -q tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RcTGoUnAo_sG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from pathlib import Path\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HwI8mUIUwzO6"
      },
      "outputs": [],
      "source": [
        "#Variables\n",
        "first_year = 2019\n",
        "last_year = 2021\n",
        "split_date =\"2021-01-01\"\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "features = [\"Underlying_last\", \"Strike\", \"Ttl\", \"Volatility\", \"R\"]\n",
        "num_features = len(features)\n",
        "num_outputs = 1\n",
        "seq_length = 5\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cd-EqCZ_1Bok"
      },
      "outputs": [],
      "source": [
        "def read_file(file):\n",
        "    \"\"\"Read a single file and return a dataframe\"\"\"\n",
        "    return pd.read_csv(file, skipinitialspace=True)\n",
        "\n",
        "def lag_features(df, features, seq_length):\n",
        "    \"\"\"Transforms a raw 2D dataframe of option data into 2D dataframe ofsequence data.\n",
        "    Last 2 indexes per sequence are bid and ask price. The len(features)*seq_length\n",
        "    features before are sequences of features\"\"\"\n",
        "    df = df.sort_values([\"Expire_date\", \"Strike\", \"Ttl\"], ascending = [True, True, False])\n",
        "\n",
        "    for step in range(seq_length)[::-1]:\n",
        "        for feature in features:\n",
        "            df[feature + \"-\" + str(step)] = df[feature].shift(step)\n",
        "    \n",
        "    df[\"Check_strike\"] = df[\"Strike\"] == df[\"Strike\"].shift(seq_length-1)\n",
        "    df[\"Check_expire\"] = df[\"Expire_date\"] == df[\"Expire_date\"].shift(seq_length-1)\n",
        "    df = df[(df[\"Check_strike\"] == True) & (df[\"Check_expire\"] == True)]\n",
        "    df = df.drop([\"Check_strike\", \"Check_expire\"], axis=1)\n",
        "    #df[[\"Bid_strike_last\", \"Ask_strike_last\"]] = df[[\"Bid_strike\", \"Ask_strike\"]]\n",
        "    #df[[\"Bid_last\", \"Ask_last\"]] = df[[\"Bid\", \"Ask\"]]\n",
        "    df[\"Price_last\"] = df[\"Price\"]\n",
        "    \n",
        "    return df\n",
        "\n",
        "def create_train_test(df, split_date):\n",
        "    \"\"\"Splits data in training and test set, and transforms data to right 2D format\"\"\"\n",
        "    return df[df[\"Quote_date\"] < split_date], df[df[\"Quote_date\"] >= split_date]\n",
        "\n",
        "def df_to_xy(df, num_features, num_outputs):\n",
        "    \"\"\"Transforms a dataframe into two arrays of explanatory variables x and explained variables y\"\"\"\n",
        "    dx = df[[\"Underlying_last\", \"Strike\", \"Ttl\", \"Volatility\", \"R\"]]\n",
        "    dy = df[\"Price\"]\n",
        "    array_x, array_y = dx.to_numpy().astype(np.float32), dy.to_numpy().astype(np.float32)\n",
        "    return array_x, array_y\n",
        "\n",
        "def min_max_scale(train, test):\n",
        "    \"\"\"Scales a training and test set using MinMaxScaler. The scaler is calibrated on the training set\"\"\"\n",
        "    scaler = MinMaxScaler()\n",
        "    train = scaler.fit_transform(train)\n",
        "    test = scaler.transform(test)\n",
        "    return train, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUf4mmpspOVv",
        "outputId": "62b87b7a-6054-4a19-acdb-4a94b7ad1e7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         Unnamed: 0  Quote_date Expire_date     Price  Underlying_last  \\\n",
            "0           1354913  2019-01-02  2019-01-04  1707.050          2509.98   \n",
            "1           1354914  2019-01-02  2019-01-04  1607.495          2509.98   \n",
            "2           1354915  2019-01-02  2019-01-04  1507.500          2509.98   \n",
            "3           1354916  2019-01-02  2019-01-04  1458.295          2509.98   \n",
            "4           1354917  2019-01-02  2019-01-04  1408.300          2509.98   \n",
            "...             ...         ...         ...       ...              ...   \n",
            "5123793     6521988  2021-12-31  2024-12-20   150.000          4766.39   \n",
            "5123794     6521989  2021-12-31  2024-12-20   150.000          4766.39   \n",
            "5123795     6521990  2021-12-31  2024-12-20   150.900          4766.39   \n",
            "5123796     6521991  2021-12-31  2024-12-20   150.000          4766.39   \n",
            "5123797     6521992  2021-12-31  2024-12-20   150.000          4766.39   \n",
            "\n",
            "         Strike   Ttl  Volatility     R  \n",
            "0         800.0     2    0.202726  2.40  \n",
            "1         900.0     2    0.202726  2.40  \n",
            "2        1000.0     2    0.202726  2.40  \n",
            "3        1050.0     2    0.202726  2.40  \n",
            "4        1100.0     2    0.202726  2.40  \n",
            "...         ...   ...         ...   ...  \n",
            "5123793  8400.0  1085    0.136456  0.97  \n",
            "5123794  8600.0  1085    0.136456  0.97  \n",
            "5123795  8800.0  1085    0.136456  0.97  \n",
            "5123796  9000.0  1085    0.136456  0.97  \n",
            "5123797  9200.0  1085    0.136456  0.97  \n",
            "\n",
            "[5123798 rows x 9 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5123798 entries, 0 to 5123797\n",
            "Data columns (total 9 columns):\n",
            " #   Column           Dtype  \n",
            "---  ------           -----  \n",
            " 0   Unnamed: 0       int64  \n",
            " 1   Quote_date       object \n",
            " 2   Expire_date      object \n",
            " 3   Price            float64\n",
            " 4   Underlying_last  float64\n",
            " 5   Strike           float64\n",
            " 6   Ttl              int64  \n",
            " 7   Volatility       float64\n",
            " 8   R                float64\n",
            "dtypes: float64(5), int64(2), object(2)\n",
            "memory usage: 351.8+ MB\n",
            "         Unnamed: 0  Quote_date Expire_date     Price  Underlying_last  \\\n",
            "0           1354913  2019-01-02  2019-01-04  1707.050          2509.98   \n",
            "1           1354914  2019-01-02  2019-01-04  1607.495          2509.98   \n",
            "2           1354915  2019-01-02  2019-01-04  1507.500          2509.98   \n",
            "3           1354916  2019-01-02  2019-01-04  1458.295          2509.98   \n",
            "4           1354917  2019-01-02  2019-01-04  1408.300          2509.98   \n",
            "...             ...         ...         ...       ...              ...   \n",
            "5123793     6521988  2021-12-31  2024-12-20   150.000          4766.39   \n",
            "5123794     6521989  2021-12-31  2024-12-20   150.000          4766.39   \n",
            "5123795     6521990  2021-12-31  2024-12-20   150.900          4766.39   \n",
            "5123796     6521991  2021-12-31  2024-12-20   150.000          4766.39   \n",
            "5123797     6521992  2021-12-31  2024-12-20   150.000          4766.39   \n",
            "\n",
            "         Strike   Ttl  Volatility     R  \n",
            "0         800.0     2    0.202726  2.40  \n",
            "1         900.0     2    0.202726  2.40  \n",
            "2        1000.0     2    0.202726  2.40  \n",
            "3        1050.0     2    0.202726  2.40  \n",
            "4        1100.0     2    0.202726  2.40  \n",
            "...         ...   ...         ...   ...  \n",
            "5123793  8400.0  1085    0.136456  0.97  \n",
            "5123794  8600.0  1085    0.136456  0.97  \n",
            "5123795  8800.0  1085    0.136456  0.97  \n",
            "5123796  9000.0  1085    0.136456  0.97  \n",
            "5123797  9200.0  1085    0.136456  0.97  \n",
            "\n",
            "[5123798 rows x 9 columns]\n",
            "1095\n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "df_read = read_file(\"data/processed_data/2019-2021_underlying-strike_only-price.csv\")\n",
        "print(df_read)\n",
        "df_read.info()\n",
        "print(df_read)\n",
        "print(df_read[\"Ttl\"].max())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEPU0KkgpQXH",
        "outputId": "7c661fbc-dc98-4008-e030-97997bb01bbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       Quote_date     Price  Underlying_last  Strike  Ttl  Volatility    R\n",
            "24524  2019-01-08  1072.110          2574.26  1500.0    1    0.215077  2.4\n",
            "24525  2019-01-08  1022.110          2574.26  1550.0    1    0.215077  2.4\n",
            "24526  2019-01-08   972.100          2574.26  1600.0    1    0.215077  2.4\n",
            "24527  2019-01-08   922.895          2574.26  1650.0    1    0.215077  2.4\n",
            "24528  2019-01-08   872.100          2574.26  1700.0    1    0.215077  2.4          Quote_date     Price  Underlying_last  Strike  Ttl  Volatility     R\n",
            "3097811  2021-01-04  2701.855          3701.38  1000.0    2    0.185353  0.09\n",
            "3104882  2021-01-05  2726.195          3727.05  1000.0    1    0.184968  0.08\n",
            "3097812  2021-01-04  2598.795          3701.38  1100.0    2    0.185353  0.09\n",
            "3104883  2021-01-05  2626.705          3727.05  1100.0    1    0.184968  0.08\n",
            "3097813  2021-01-04  2500.195          3701.38  1200.0    2    0.185353  0.09\n",
            "-------\n",
            " [[2.5742600e+03 1.5000000e+03 1.0000000e+00 2.1507716e-01 2.4000001e+00]\n",
            " [2.5742600e+03 1.5500000e+03 1.0000000e+00 2.1507716e-01 2.4000001e+00]\n",
            " [2.5742600e+03 1.6000000e+03 1.0000000e+00 2.1507716e-01 2.4000001e+00]\n",
            " ...\n",
            " [3.7275200e+03 6.4000000e+03 1.0810000e+03 1.8352406e-01 1.7000000e-01]\n",
            " [3.7324099e+03 6.4000000e+03 1.0800000e+03 1.8329987e-01 1.7000000e-01]\n",
            " [3.7563101e+03 6.4000000e+03 1.0790000e+03 1.8348454e-01 1.7000000e-01]] [1072.11  1022.11   972.1   ...   15.495   14.995   18.75 ]\n",
            "Train_x shape: (2785226, 5), train_y shape: (2785226,)\n",
            "Test_x shape: (1845482, 5), test_y shape: (1845482,)\n"
          ]
        }
      ],
      "source": [
        "# Splitting dataset\n",
        "df_read = lag_features(df_read, features, seq_length)\n",
        "df_read = df_read[[\"Quote_date\", \"Price\", \"Underlying_last\", \"Strike\", \"Ttl\", \"Volatility\", \"R\"]]\n",
        "df_train_orginal, df_test_orginal = create_train_test(df_read, split_date)\n",
        "print(df_train_orginal.head(), df_test_orginal.head())\n",
        "\n",
        "train_x_org, train_y_org, = df_to_xy(df_train_orginal, num_features, num_outputs)\n",
        "print(\"-------\\n\", train_x_org, train_y_org)\n",
        "test_x_org, test_y_org = df_to_xy(df_test_orginal, num_features, num_outputs)\n",
        "\n",
        "train_x_scaled, test_x_scaled = min_max_scale(train_x_org, test_x_org)\n",
        "#train_y_scaled, test_y_scaled = min_max_scale(train_y_org, test_y_org)\n",
        "train_y_scaled, test_y_scaled = train_y_org, test_y_org\n",
        "\n",
        "\"\"\"shuffle = np.random.permutation(len(train_x_scaled))\n",
        "train_x_scaled, train_y_scaled = train_x_scaled[shuffle], train_y_scaled[shuffle]\"\"\"\n",
        "\n",
        "train_x_scaled = np.reshape(train_x_scaled, (len(train_x_scaled), num_features))\n",
        "test_x_scaled = np.reshape(test_x_scaled, (len(test_x_scaled), num_features))\n",
        "\n",
        "print(f\"Train_x shape: {train_x_scaled.shape}, train_y shape: {train_y_scaled.shape}\")\n",
        "print(f\"Test_x shape: {test_x_scaled.shape}, test_y shape: {test_y_scaled.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "5ai3RgkWpVA3",
        "outputId": "a5f563c2-18c3-4626-c7b7-6fc747bc467e"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input, Dropout, BatchNormalization\n",
        "from keras import backend as K\n",
        "from tensorflow_addons.optimizers import AdamW\n",
        "import keras as KER\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.activations import linear, relu\n",
        "from datetime import datetime\n",
        "from tensorflow.keras.metrics import MeanSquaredError, RootMeanSquaredError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wtvth-7Vz87q"
      },
      "outputs": [],
      "source": [
        "def create_model(config):\n",
        "  \"\"\"Builds a model of minimum 2 layers sequentially from a given config dictionary\"\"\"\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(\n",
        "    units = config[\"units\"],\n",
        "    activation = relu,\n",
        "    input_shape = (config[\"num_features\"],)\n",
        "  ))\n",
        "\n",
        "  model.add(BatchNormalization(\n",
        "    momentum = config[\"bn_momentum\"]\n",
        "  ))\n",
        "\n",
        "\n",
        "  for i in range(config[\"layers\"]-2):\n",
        "    model.add(Dense(\n",
        "      units = config[\"units\"],\n",
        "      activation = relu\n",
        "    ))\n",
        "    model.add(BatchNormalization(\n",
        "      momentum = config[\"bn_momentum\"]\n",
        "    ))\n",
        "\n",
        "  model.add(Dense(\n",
        "    units = config[\"units\"],\n",
        "    activation = relu\n",
        "  ))\n",
        "\n",
        "  model.add(BatchNormalization(\n",
        "    momentum = config[\"bn_momentum\"]\n",
        "  ))\n",
        "\n",
        "  model.add(Dense(\n",
        "    units = num_outputs,\n",
        "    activation = relu\n",
        "  ))  \n",
        "\n",
        "  model.compile(\n",
        "    optimizer = AdamW(\n",
        "      learning_rate = config[\"learning_rate\"],\n",
        "      weight_decay = config[\"weight_decay\"]\n",
        "    ),\n",
        "    loss = \"mse\",\n",
        "  )\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMFVcYRHpWNo",
        "outputId": "158d9438-08de-4d33-9f64-3bc2f2460ee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_15 (Dense)            (None, 32)                192       \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 32)               128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 32)                1056      \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 32)               128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 32)                1056      \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 32)               128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 32)                1056      \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 32)               128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,905\n",
            "Trainable params: 3,649\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "952/952 [==============================] - 7s 6ms/step - loss: 113062.5547 - val_loss: 7794.5557\n",
            "Epoch 2/100\n",
            "952/952 [==============================] - 6s 6ms/step - loss: 394.1487 - val_loss: 10779.2734\n",
            "Epoch 3/100\n",
            "952/952 [==============================] - 6s 6ms/step - loss: 336.8996 - val_loss: 9542.7080\n",
            "Epoch 4/100\n",
            "952/952 [==============================] - 5s 5ms/step - loss: 303.4823 - val_loss: 5824.7021\n",
            "Epoch 5/100\n",
            "952/952 [==============================] - 5s 6ms/step - loss: 303.1941 - val_loss: 6102.9863\n",
            "Epoch 6/100\n",
            "952/952 [==============================] - 5s 5ms/step - loss: 297.0577 - val_loss: 862.8143\n",
            "Epoch 7/100\n",
            "952/952 [==============================] - 5s 6ms/step - loss: 300.5722 - val_loss: 1103.1871\n",
            "Epoch 8/100\n",
            "952/952 [==============================] - 7s 7ms/step - loss: 297.9997 - val_loss: 944.8633\n",
            "Epoch 9/100\n",
            "952/952 [==============================] - 9s 10ms/step - loss: 289.4884 - val_loss: 1804.0964\n",
            "Epoch 10/100\n",
            "952/952 [==============================] - 7s 7ms/step - loss: 285.5909 - val_loss: 2463.9810\n",
            "Epoch 11/100\n",
            "952/952 [==============================] - 6s 6ms/step - loss: 286.9356 - val_loss: 771.6089\n",
            "Epoch 12/100\n",
            "952/952 [==============================] - 6s 7ms/step - loss: 299.9817 - val_loss: 1571.3640\n",
            "Epoch 13/100\n",
            "952/952 [==============================] - 5s 6ms/step - loss: 294.0575 - val_loss: 926.3049\n",
            "Epoch 14/100\n",
            "952/952 [==============================] - 6s 6ms/step - loss: 287.4159 - val_loss: 724.4841\n",
            "Epoch 15/100\n",
            "952/952 [==============================] - 6s 6ms/step - loss: 300.2062 - val_loss: 754.5220\n",
            "Epoch 16/100\n",
            "952/952 [==============================] - 5s 6ms/step - loss: 294.8610 - val_loss: 1940.2977\n",
            "Epoch 17/100\n",
            "952/952 [==============================] - 5s 6ms/step - loss: 289.5281 - val_loss: 676.1246\n",
            "Epoch 18/100\n",
            "952/952 [==============================] - 5s 6ms/step - loss: 278.3647 - val_loss: 856.1624\n",
            "Epoch 19/100\n",
            "952/952 [==============================] - 6s 6ms/step - loss: 271.7689 - val_loss: 732.1286\n",
            "Epoch 20/100\n",
            "952/952 [==============================] - 5s 6ms/step - loss: 300.8791 - val_loss: 814.8387\n",
            "Epoch 21/100\n",
            "952/952 [==============================] - 5s 6ms/step - loss: 287.6797 - val_loss: 648.8984\n",
            "Epoch 22/100\n",
            "952/952 [==============================] - 5s 6ms/step - loss: 295.1062 - val_loss: 804.0759\n",
            "Epoch 23/100\n",
            "952/952 [==============================] - 6s 7ms/step - loss: 270.8157 - val_loss: 1104.8680\n",
            "Epoch 24/100\n",
            "952/952 [==============================] - 6s 6ms/step - loss: 282.7975 - val_loss: 1543.4266\n",
            "Epoch 25/100\n",
            "952/952 [==============================] - 6s 6ms/step - loss: 310.8810 - val_loss: 1272.3527\n",
            "Epoch 26/100\n",
            "952/952 [==============================] - 5s 6ms/step - loss: 277.7194 - val_loss: 1255.1125\n",
            "Epoch 27/100\n",
            "952/952 [==============================] - 7s 7ms/step - loss: 279.4805 - val_loss: 1092.5189\n",
            "Epoch 28/100\n",
            "952/952 [==============================] - 7s 7ms/step - loss: 282.0797 - val_loss: 888.3726\n",
            "Epoch 29/100\n",
            "952/952 [==============================] - 7s 7ms/step - loss: 274.9672 - val_loss: 1881.8243\n",
            "Epoch 30/100\n",
            "952/952 [==============================] - 6s 7ms/step - loss: 279.2933 - val_loss: 1767.9049\n",
            "Epoch 31/100\n",
            "952/952 [==============================] - 7s 7ms/step - loss: 281.5244 - val_loss: 1919.9814\n",
            "Epoch 32/100\n",
            "952/952 [==============================] - 7s 7ms/step - loss: 277.6086 - val_loss: 2439.3735\n",
            "Epoch 33/100\n",
            "952/952 [==============================] - 6s 6ms/step - loss: 281.8310 - val_loss: 1474.0524\n",
            "Epoch 34/100\n",
            "952/952 [==============================] - 7s 7ms/step - loss: 283.6089 - val_loss: 1365.1663\n",
            "Epoch 35/100\n",
            "952/952 [==============================] - 6s 6ms/step - loss: 278.9134 - val_loss: 1254.8967\n",
            "Epoch 36/100\n",
            "952/952 [==============================] - 6s 6ms/step - loss: 282.3182 - val_loss: 1310.3956\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'timestamp = datetime.now().strftime(\"%d/%m/%Y_%H:%M\")\\npath = f\"{colab_path}runs/model_w_validation/{first_year}-{last_year}-{timestamp}\"\\nmodel.save(path)'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "config = {\n",
        "    \"units\": 32,\n",
        "    \"learning_rate\": 0.004588272887584361,\n",
        "    \"layers\": 4,\n",
        "    \"seq_length\": seq_length,\n",
        "    \"num_features\": num_features,\n",
        "    \"bn_momentum\" : 0.034653375084312724,\n",
        "    \"lr_decay\" : 0.9475091291542892,\n",
        "    \"weight_decay\" : 0.0001\n",
        "}\n",
        "\n",
        "def trainer(train_x, train_y, model):\n",
        "    epochs = 100\n",
        "    minibatch_size = 2048\n",
        "\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        mode='min',\n",
        "        min_delta = 1,\n",
        "        patience = 15,\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        train_x,\n",
        "        train_y,\n",
        "        batch_size = minibatch_size,\n",
        "        validation_split = 0.3,\n",
        "        epochs = epochs,\n",
        "        callbacks = [early_stopping]\n",
        "    )\n",
        "\n",
        "model = create_model(config)\n",
        "model.summary()\n",
        "\n",
        "trainer(train_x_scaled, train_y_org, model)\n",
        "\n",
        "\"\"\"timestamp = datetime.now().strftime(\"%d/%m/%Y_%H:%M\")\n",
        "path = f\"{colab_path}runs/model_w_validation/{first_year}-{last_year}-{timestamp}\"\n",
        "model.save(path)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-G13GuDUvEi"
      },
      "outputs": [],
      "source": [
        "predictions = np.array(model(test_x_scaled))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17p20nE8yLxu",
        "outputId": "13a90785-3b58-44e8-c054-762cb82a60ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE from model: 3797.985\n",
            "RMSE from model: 61.627796\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-58-2acf95ef6ca3>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_test[\"Prediction\"] = predictions.flatten()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'timestamp = datetime.now().strftime(\"%d/%m/%Y_%H:%M\")\\nfilename = f\"{colab_path}runs/data_w_validation/{first_year}-{last_year}-{timestamp}.csv\"\\nfilepath = Path(filename)  \\nfilepath.parent.mkdir(parents=True, exist_ok=True)  \\ndf_test.to_csv(filename)\\n'"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def prediction(df_test, predictions, model, train_y_org, test_y_org):\n",
        "    df_test[\"Prediction\"] = predictions.flatten()\n",
        "\n",
        "    m = MeanSquaredError()\n",
        "    m.update_state(test_y_org, predictions)\n",
        "    print(\"MSE from model:\", m.result().numpy())\n",
        "    m = RootMeanSquaredError()\n",
        "    m.update_state(test_y_org, predictions)\n",
        "    print(\"RMSE from model:\", m.result().numpy())\n",
        "\n",
        "    return df_test\n",
        "\n",
        "df_test = prediction(df_test_orginal, predictions, model, train_y_org, test_y_org)\n",
        "\n",
        "#print(train_y_org[:, :1].min(), train_y_org[:, :1].max())\n",
        "#print(train_y_org[:, 1:].min(), train_y_org[:, 1:].max())\n",
        "\n",
        "\"\"\"print(\"MSE_bid:\", df_test[\"SE_bid\"].mean(), \"RMSE_bid:\", math.sqrt(df_test[\"SE_bid\"].mean()))\n",
        "print(\"MSE_ask:\", df_test[\"SE_ask\"].mean(), \"RMSE_ask:\", math.sqrt(df_test[\"SE_ask\"].mean()))\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"timestamp = datetime.now().strftime(\"%d/%m/%Y_%H:%M\")\n",
        "filename = f\"{colab_path}runs/data_w_validation/{first_year}-{last_year}-{timestamp}.csv\"\n",
        "filepath = Path(filename)  \n",
        "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
        "df_test.to_csv(filename)\n",
        "\"\"\"\n",
        "#df_test.info()\n",
        "#print(df_test.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pktgxPmgP8A9",
        "outputId": "a6791327-476b-4baa-9d94-afa56c83cf5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 32)                192       \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 32)               128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 32)               128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 32)               128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,721\n",
            "Trainable params: 2,529\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n",
            "Epoch 1/4\n",
            "1513/1513 [==============================] - 10s 5ms/step - loss: 112382.0469\n",
            "Epoch 2/4\n",
            "1513/1513 [==============================] - 8s 5ms/step - loss: 518.7962\n",
            "Epoch 3/4\n",
            "1513/1513 [==============================] - 8s 5ms/step - loss: 478.3040\n",
            "Epoch 4/4\n",
            "1513/1513 [==============================] - 8s 5ms/step - loss: 438.4208\n"
          ]
        }
      ],
      "source": [
        "def trainer2(train_x, train_y, model):\n",
        "    epochs = 24\n",
        "    minibatch_size = 2048\n",
        "\n",
        "    model.fit(\n",
        "        train_x,\n",
        "        train_y,\n",
        "        batch_size = minibatch_size,\n",
        "        epochs = epochs\n",
        "    )\n",
        "\n",
        "model2 = create_model(config)\n",
        "model2.summary()\n",
        "\n",
        "trainer2(train_x_scaled, train_y_org, model2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IS6Qb7PLQKFf"
      },
      "outputs": [],
      "source": [
        "predictions2 = np.array(model2(test_x_scaled))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzX_LcF7QLnn",
        "outputId": "34a17282-5b71-48eb-e186-9bcceacdb1b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE from model: 1634.7479\n",
            "RMSE from model: 40.432014\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-61-882d3b969251>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_test[\"Prediction\"] = predictions.flatten()\n"
          ]
        }
      ],
      "source": [
        "def prediction(df_test, predictions, model, train_y_org, test_y_org):\n",
        "    df_test[\"Prediction\"] = predictions.flatten()\n",
        "\n",
        "    m = MeanSquaredError()\n",
        "    m.update_state(test_y_org, predictions)\n",
        "    print(\"MSE from model:\", m.result().numpy())\n",
        "    m = RootMeanSquaredError()\n",
        "    m.update_state(test_y_org, predictions)\n",
        "    print(\"RMSE from model:\", m.result().numpy())\n",
        "\n",
        "    return df_test\n",
        "\n",
        "df_test2 = prediction(df_test_orginal, predictions2, model2, train_y_org, test_y_org)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6ktCzkt7OxK"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2geWTt27ZRZ"
      },
      "outputs": [],
      "source": [
        "time = datetime.now()\n",
        "time = time.strftime(\"%m-%d_%H-%M\")\n",
        "\n",
        "filename = f\"{colab_path}Predictions/{last_year}_predictions_{time}.csv\"\n",
        "filepath = Path(filename)\n",
        "filepath.parent.mkdir(parents=True, exist_ok = True)\n",
        "df_test2.to_csv(filename)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.1 ('A_Star-bay7YQ3K')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "346f1978fc3949933b17c75d4815baa97117852380bde1b98c856e676f6b5766"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
