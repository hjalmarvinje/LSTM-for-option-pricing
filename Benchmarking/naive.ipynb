{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run #1 in order of benchmarking\n",
    "\n",
    "This file processes the existing processed datafile, adds laggs and filters for 2021, and then removes some columns, then returns the file in the benchmark folder. This file is later used by the BS file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : Unable to import these functions in parent directory\n",
    "\n",
    "def lag_features(df, features, seq_length):\n",
    "    \"\"\"Transforms a raw 2D dataframe of option data into 2D dataframe ofsequence data.\n",
    "    Last 2 indexes per sequence are bid and ask price. The len(features)*seq_length\n",
    "    features before are sequences of features\"\"\"\n",
    "    df = df.sort_values([\"Expire_date\", \"Strike\", \"Ttl\"], ascending = [True, True, False])\n",
    "    \n",
    "    # Adding lag for naive benchmarking\n",
    "    df[\"Naive\"] = df[\"Price\"].shift(1)\n",
    "\n",
    "    for step in range(seq_length)[::-1]:\n",
    "        for feature in features:\n",
    "            df[feature + \"-\" + str(step)] = df[feature].shift(step)\n",
    "    \n",
    "    df[\"Check_strike\"] = df[\"Strike\"] == df[\"Strike\"].shift(seq_length-1)\n",
    "    df[\"Check_expire\"] = df[\"Expire_date\"] == df[\"Expire_date\"].shift(seq_length-1)\n",
    "    df = df[(df[\"Check_strike\"] == True) & (df[\"Check_expire\"] == True)]\n",
    "    df = df.drop([\"Check_strike\", \"Check_expire\"], axis=1)\n",
    "    #df[[\"Bid_strike_last\", \"Ask_strike_last\"]] = df[[\"Bid_strike\", \"Ask_strike\"]]\n",
    "    #df[[\"Bid_last\", \"Ask_last\"]] = df[[\"Bid\", \"Ask\"]]\n",
    "    df[\"Price_last\"] = df[\"Price\"]\n",
    "    df = df.sort_values([\"Quote_date\"], ascending = [True])\n",
    "    return df\n",
    "\n",
    "    \n",
    "def read_file(file):\n",
    "    \"\"\"Read a single file and return a dataframe\"\"\"\n",
    "    return pd.read_csv(file, skipinitialspace=True)\n",
    "\n",
    "\n",
    "\n",
    "from math import log, sqrt, pi, exp\n",
    "from scipy.stats import norm\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = f\"../data/predictions/2021_predictions_11-21_12-51.csv\"\n",
    "df_options = read_file(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Underlying_last\", \"Strike\", \"Ttl\", \"Volatility\", \"R\"]\n",
    "seq_length = 5\n",
    "num_features = len(features)\n",
    "num_outputs = 1\n",
    "\n",
    "df_options = lag_features(df_options, features, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_options = df_options[[\"Quote_date\", \"Underlying_last\", \"Strike\", \"Ttl\", \"Volatility\", \"R\", \"Price\", \"Naive\", \"Prediction\"]]\n",
    "df_options['Quote_date'] = pd.to_datetime(df_options.Quote_date, format='%Y-%m-%d')\n",
    "df_options = df_options[df_options.Quote_date.dt.year == 2021]\n",
    "\n",
    "# To be used for testing on for faster computing\n",
    "#df_options_short = df_options[df_options[\"Quote_date\"] == \"2021-01-06\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Quote_date  Underlying_last  Strike  Ttl  Volatility     R     Price  \\\n",
      "1429  2021-01-08          3824.45  1000.0    3    0.186024  0.08  2826.250   \n",
      "79288 2021-01-08          3824.45  3860.0   49    0.186024  0.08    75.200   \n",
      "79325 2021-01-08          3824.45  3865.0   49    0.186024  0.08    72.955   \n",
      "79362 2021-01-08          3824.45  3870.0   49    0.186024  0.08    70.550   \n",
      "79399 2021-01-08          3824.45  3875.0   49    0.186024  0.08    67.495   \n",
      "\n",
      "          Naive   Prediction  \n",
      "1429   2803.855  2774.402600  \n",
      "79288    67.900    69.269806  \n",
      "79325    65.210    66.548515  \n",
      "79362    63.055    63.835953  \n",
      "79399    60.500    61.140602  \n"
     ]
    }
   ],
   "source": [
    "print(df_options.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_bs = tf.keras.metrics.mean_squared_error(\n",
    "    df_options[\"Price\"], df_options[\"Naive\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  tf.Tensor(784.3698665832319, shape=(), dtype=float64)\n",
      "RMSE:  28.006603981618905\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE: \", mse_bs)\n",
    "print(\"RMSE: \", sqrt(mse_bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f3a9023fdddf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Write to file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results.tex'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m      \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_latex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Write to file\n",
    "df_options.to_csv('data/benchmark_with_pred_naive.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
